{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPGdPavVo7XR",
    "outputId": "8869b575-b5a0-4018-ecf2-023e502fd706"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6n4dQW5_pGz7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv \n",
    "import time\n",
    "import copy\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "#from pytorch_model_summary import summary\n",
    "from tqdm import trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dreem_functions.visualisation import SIGNALS_NAME, extract_events_from_binary_mask, \\\n",
    "                                          visualize_signal_and_event, visualise_index\n",
    "from Dreem_functions.metric_dreem  import jaccard_overlap, extract_events_from_binary_mask, \\\n",
    "                                          compute_f1_score, compute_tp_fp_fn_for_each_entry,\\\n",
    "                                          format_predictions_for_scoring, dreem_sleep_apnea_custom_metric\n",
    "from Our_functions.create_tensors  import normalize_dim, normalize_ppson, compute_spectrograms\n",
    "from Our_functions.create_datasets import create_dataset, create_3_part_dataset, create_4_part_dataset, \\\n",
    "                                          create_loader\n",
    "from Our_functions.raw_models      import RawCNN, GruCNN\n",
    "from Our_functions.new_raw_models  import Unet\n",
    "from Our_functions.fft_models      import fftCNN\n",
    "from Our_functions.dual_models     import DualCNN\n",
    "from Our_functions.loss_functions  import DiceBCELoss, TverskyLoss, FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R814vvkho-rc"
   },
   "outputs": [],
   "source": [
    "# Visualize signals\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (18, 9)\n",
    "\n",
    "PATH_TO_TRAINING_DATA = \"Data sets/additional_files_dreem/X_train.h5\"\n",
    "PATH_TO_TRAINING_TARGET = \"Data sets/Training/y_train_tX9Br0C.csv\"\n",
    "h5_file = h5py.File(PATH_TO_TRAINING_DATA)\n",
    "mask = np.array(pd.read_csv(PATH_TO_TRAINING_TARGET))\n",
    "visualise_index(0, h5_file, mask)\n",
    "visualise_index(18, h5_file, mask)\n",
    "visualise_index(52, h5_file, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lvrIROZleqd",
    "outputId": "e1866708-426b-4848-d659-3d28d58c7b31"
   },
   "outputs": [],
   "source": [
    "# Create training data\n",
    "print(\"Train set...\")\n",
    "\n",
    "PATH_TO_TRAINING_DATA = \"Data sets/additional_files_dreem/X_train.h5\"\n",
    "train_file = h5py.File(PATH_TO_TRAINING_DATA)\n",
    "\n",
    "train_set = train_file['data'][:, 2:]\n",
    "\n",
    "train_set_raw = train_set.reshape((4400, 8, 9000))\n",
    "#train_set_fft = compute_spectrograms(train_set_raw, status='mel', verbose=True)\n",
    "train_set_raw = normalize_ppson(train_set_raw)\n",
    "\n",
    "\n",
    "# Create testing data\n",
    "print(\"Test  set...\")\n",
    "\n",
    "PATH_TO_TESTING_DATA = \"Data sets/additional_files_dreem/X_test.h5\"\n",
    "test_file = h5py.File(PATH_TO_TESTING_DATA)\n",
    "\n",
    "test_set = test_file['data'][:, 2:]\n",
    "\n",
    "test_set_raw = test_set.reshape((4400, 8, 9000))\n",
    "#test_set_fft = compute_spectrograms(test_set_raw, status='mel', verbose=False)\n",
    "test_set_raw = normalize_ppson(test_set_raw)\n",
    "\n",
    "\n",
    "# Create training label\n",
    "PATH_TO_TRAINING_TARGET = \"Data sets/Training/y_train_tX9Br0C.csv\"\n",
    "masks = np.array(pd.read_csv(PATH_TO_TRAINING_TARGET))\n",
    "masks = np.array(masks[:, 1:])\n",
    "\n",
    "print(\"1D Input  shapes: {}\".format(train_set_raw.shape))\n",
    "#print(\"2D Input  shapes: {}\".format(train_set_fft.shape))\n",
    "print(\"Output    shapes: {}\".format(masks.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sig0 = train_set_raw[:, 0, :].reshape((4400, 1, 9000))\n",
    "train_sig1 = train_set_raw[:, 1, :].reshape((4400, 1, 9000))\n",
    "train_sig2 = train_set_raw[:, 2, :].reshape((4400, 1, 9000))\n",
    "train_sig3 = train_set_raw[:, 3, :].reshape((4400, 1, 9000))\n",
    "train_sig4 = train_set_raw[:, 4, :].reshape((4400, 1, 9000))\n",
    "train_sig5 = train_set_raw[:, 5, :].reshape((4400, 1, 9000))\n",
    "train_sig6 = train_set_raw[:, 6, :].reshape((4400, 1, 9000))\n",
    "train_sig7 = train_set_raw[:, 7, :].reshape((4400, 1, 9000))\n",
    "\n",
    "test_sig0 = test_set_raw[:, 0, :].reshape((4400, 1, 9000))\n",
    "test_sig1 = test_set_raw[:, 1, :].reshape((4400, 1, 9000))\n",
    "test_sig2 = test_set_raw[:, 2, :].reshape((4400, 1, 9000))\n",
    "test_sig3 = test_set_raw[:, 3, :].reshape((4400, 1, 9000))\n",
    "test_sig4 = test_set_raw[:, 4, :].reshape((4400, 1, 9000))\n",
    "test_sig5 = test_set_raw[:, 5, :].reshape((4400, 1, 9000))\n",
    "test_sig6 = test_set_raw[:, 6, :].reshape((4400, 1, 9000))\n",
    "test_sig7 = test_set_raw[:, 7, :].reshape((4400, 1, 9000))\n",
    "\n",
    "print(train_sig0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_set = np.concatenate((train_sig0, train_sig1, train_sig2, train_sig3, train_sig5), axis=1)\n",
    "new_test_set  = np.concatenate((test_sig0, test_sig1, test_sig2, test_sig3, test_sig5), axis=1)\n",
    "\n",
    "print(new_train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKRu9yMq1tII",
    "outputId": "a56f0fc0-4018-4b9f-c6cf-be3544cebaf7"
   },
   "outputs": [],
   "source": [
    "# Create dataset. Splitting into 5 for ensemble method.\n",
    "train_dataset_dual = create_dataset(train_set_raw, masks)\n",
    "\n",
    "splits_dual = torch.utils.data.random_split(train_dataset_dual, [880, 880, 880, 880, 880], generator=torch.Generator().manual_seed(11))\n",
    "print(splits_dual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpd7QpWnWkEM",
    "outputId": "0f571198-fa01-4bea-df06-7d42e33a0351"
   },
   "outputs": [],
   "source": [
    "rawmodel = RawCNN().cuda()\n",
    "\n",
    "summary(rawmodel, (8, 9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grumodel = GruCNN().cuda()\n",
    "\n",
    "summary(grumodel, (8, 9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unetmodel = Unet().cuda()\n",
    "\n",
    "summary(unetmodel, (8, 9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftmodel = fftCNN().cuda()\n",
    "\n",
    "summary(fftmodel, (8, 8, 900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEgic-h4gPt2"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, model_index):\n",
    "    model_file = 'Results/new_experiment' + '/' + 'grucnn_' + str(model_index) + '.pth'\n",
    "    \n",
    "    criterion = TverskyLoss() # alternative: look at loss_functions.py or torch.nn.BCELoss()\n",
    "    #criterion = nn.BCELoss()\n",
    "    \n",
    "    lr = 0.0001\n",
    "        \n",
    "    since = time.time()\n",
    "    num_epochs = 300\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "    best_acc = 0.\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_acc = 0.0\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                \n",
    "                full_loss = 0.\n",
    "                full_acc  = 0.\n",
    "                \n",
    "                for batch_idx, (raw, target) in enumerate(train_loader):\n",
    "                    if use_cuda:\n",
    "                        raw, target = raw.cuda(), target.cuda()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Input varies depending on network used\n",
    "                    output = model(raw)\n",
    "                    \n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    full_loss += loss\n",
    "\n",
    "                    cpu_output       = output.cpu().detach().numpy()\n",
    "                    cpu_output       = np.rint(cpu_output)\n",
    "                    cpu_output       = cpu_output.astype(int)\n",
    "                    \n",
    "                    try:\n",
    "                        cpu_output   = format_predictions_for_scoring(cpu_output)\n",
    "                    except:\n",
    "                        cpu_output   = 0.\n",
    "                    \n",
    "                    cpu_target       = target.cpu().detach().numpy()\n",
    "                    cpu_target       = np.rint(cpu_target)\n",
    "                    cpu_target       = cpu_target.astype(int)\n",
    "                    \n",
    "                    try:\n",
    "                        cpu_target   = format_predictions_for_scoring(cpu_target)\n",
    "                    except:\n",
    "                        cpu_target   = 0.\n",
    "                    \n",
    "                    full_acc  += compute_f1_score(cpu_output, cpu_target)\n",
    "                \n",
    "                full_loss = full_loss / (batch_idx + 1)\n",
    "                full_acc  = full_acc  / (batch_idx + 1)\n",
    "\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "                # Compute validation loss\n",
    "                validation_loss = 0\n",
    "                validation_acc  = 0\n",
    "                \n",
    "                for batch_idx, (raw, target) in enumerate(val_loader):\n",
    "                    if use_cuda:\n",
    "                        raw, target = raw.cuda(), target.cuda()\n",
    "\n",
    "                    # Input varies depending on network used\n",
    "                    output = model(raw)\n",
    "                    \n",
    "                    validation_loss += criterion(output, target).item()\n",
    "                    \n",
    "                    cpu_output       = output.cpu().detach().numpy()\n",
    "                    cpu_output       = np.rint(cpu_output)\n",
    "                    cpu_output       = cpu_output.astype(int)\n",
    "                    \n",
    "                    try:\n",
    "                        cpu_output   = format_predictions_for_scoring(cpu_output)\n",
    "                    except:\n",
    "                        cpu_output   = 0.\n",
    "                    \n",
    "                    cpu_target       = target.cpu().detach().numpy()\n",
    "                    cpu_target       = np.rint(cpu_target)\n",
    "                    cpu_target       = cpu_target.astype(int)\n",
    "                    \n",
    "                    try:\n",
    "                        cpu_target   = format_predictions_for_scoring(cpu_target)\n",
    "                    except:\n",
    "                        cpu_target   = 0.\n",
    "                    \n",
    "                    validation_acc  += compute_f1_score(cpu_output, cpu_target)\n",
    "                    \n",
    "                validation_loss = validation_loss / (batch_idx + 1)\n",
    "                validation_acc  = validation_acc  / (batch_idx + 1)\n",
    "\n",
    "                print('Epoch {} --> train set: loss is {:.3f}. F1 score is {:.3f}, validation set: loss is {:.3f}. F1 score is: {:.3f}'.format(epoch, full_loss, full_acc, validation_loss, validation_acc))\n",
    "                \n",
    "                epoch_acc = validation_acc\n",
    "            \n",
    "            # Save model if F1 score is better\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), model_file)\n",
    "                print('--> Saved model to ' + model_file)\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NL7HjaXDQ33i",
    "outputId": "aade15c2-2793-4f00-f0a2-7552153b6c5b"
   },
   "outputs": [],
   "source": [
    "# Create experiment folder\n",
    "if not os.path.isdir('Results/new_experiment'):\n",
    "    os.makedirs('Results/new_experiment')\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "for x in range(5):\n",
    "    l = []\n",
    "\n",
    "    for i in range(5):\n",
    "        if (i == x):\n",
    "            continue\n",
    "        else:\n",
    "            l.append(splits_dual[i])\n",
    "\n",
    "    models = GruCNN()\n",
    "\n",
    "    if (use_cuda == True):\n",
    "      models.cuda()\n",
    "    \n",
    "    set_to_use = torch.utils.data.ConcatDataset(l)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(set_to_use, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "    val_loader = torch.utils.data.DataLoader(splits_dual[x], batch_size=batch_size, shuffle=False)    \n",
    "    models = train_model(models, train_loader, val_loader, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4zrjQCehOXy",
    "outputId": "c1f79ec2-0ff1-4dfa-bcdb-b43c2c37015a"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "model1 = GruCNN()\n",
    "state_dict1 = torch.load('Results/new_experiment/grucnn_0.pth')\n",
    "model1.load_state_dict(state_dict1)\n",
    "model1.eval()\n",
    "\n",
    "model2 = GruCNN()\n",
    "state_dict2 = torch.load('Results/new_experiment/grucnn_1.pth')\n",
    "model2.load_state_dict(state_dict2)\n",
    "model2.eval()\n",
    "\n",
    "model3 = GruCNN()\n",
    "state_dict3 = torch.load('Results/new_experiment/grucnn_2.pth')\n",
    "model3.load_state_dict(state_dict3)\n",
    "model3.eval()\n",
    "\n",
    "model4 = GruCNN()\n",
    "state_dict4 = torch.load('Results/new_experiment/grucnn_3.pth')\n",
    "model4.load_state_dict(state_dict4)\n",
    "model4.eval()\n",
    "\n",
    "model5 = GruCNN()\n",
    "state_dict5 = torch.load('Results/new_experiment/grucnn_4.pth')\n",
    "model5.load_state_dict(state_dict5)\n",
    "model5.eval()\n",
    "\n",
    "outfile = 'Results/new_experiment/final_gru_results.csv'\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    model1.cuda()\n",
    "    model2.cuda()\n",
    "    model3.cuda()\n",
    "    model4.cuda()\n",
    "    model5.cuda()\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "output_file = open(outfile, \"w\")\n",
    "output_file.write(\"ID,y_0,y_1,y_2,y_3,y_4,y_5,y_6,y_7,y_8,y_9,y_10,y_11,y_12,y_13,y_14,y_15,y_16,y_17,y_18,y_19,\"\n",
    "                     \"y_20,y_21,y_22,y_23,y_24,y_25,y_26,y_27,y_28,y_29,y_30,y_31,y_32,y_33,y_34,y_35,y_36,y_37,\"\n",
    "                     \"y_38,y_39,y_40,y_41,y_42,y_43,y_44,y_45,y_46,y_47,y_48,y_49,y_50,y_51,y_52,y_53,y_54,y_55,\"\n",
    "                     \"y_56,y_57,y_58,y_59,y_60,y_61,y_62,y_63,y_64,y_65,y_66,y_67,y_68,y_69,y_70,y_71,y_72,y_73,\"\n",
    "                     \"y_74,y_75,y_76,y_77,y_78,y_79,y_80,y_81,y_82,y_83,y_84,y_85,y_86,y_87,y_88,y_89\\n\")\n",
    "thresh = 0.5\n",
    "\n",
    "for f in trange(test_set_raw.shape[0]):\n",
    "    raw = test_set_raw[f, :, :]\n",
    "    raw = raw.reshape((1, raw.shape[0], raw.shape[1]))\n",
    "    raw = torch.tensor(raw, dtype=torch.float)\n",
    "    \n",
    "    #fft = test_set_fft[f, :, :, :]\n",
    "    #fft = raw.reshape((1, fft.shape[0], fft.shape[1], fft.shape[2]))\n",
    "    #fft = torch.tensor(fft, dtype=torch.float)\n",
    "\n",
    "    if use_cuda:\n",
    "        raw = raw.cuda()\n",
    "    \n",
    "    output1 = model1(raw)[0].cpu().detach().numpy()\n",
    "    output1 = np.rint(output1)\n",
    "    output1 = output1.astype(int)\n",
    "    \n",
    "    output2 = model2(raw)[0].cpu().detach().numpy()\n",
    "    output2 = np.rint(output2)\n",
    "    output2 = output2.astype(int)\n",
    "    \n",
    "    output3 = model3(raw)[0].cpu().detach().numpy()\n",
    "    output3 = np.rint(output3)\n",
    "    output3 = output3.astype(int)\n",
    "    \n",
    "    output4 = model4(raw)[0].cpu().detach().numpy()\n",
    "    output4 = np.rint(output4)\n",
    "    output4 = output4.astype(int)\n",
    "    \n",
    "    output5 = model5(raw)[0].cpu().detach().numpy()\n",
    "    output5 = np.rint(output5)\n",
    "    output5 = output5.astype(int)\n",
    "\n",
    "    sum = (output1 + output2 + output3 + output4 + output5) / 5\n",
    "    sum = np.rint(sum).astype(int)\n",
    "\n",
    "    my_list = [4400+f] + list(sum)\n",
    "    my_string = ','.join(map(str, my_list)) \n",
    "\n",
    "    output_file.write(\"%s\\n\" % (my_string))\n",
    "\n",
    "output_file.close()\n",
    "\n",
    "print(\"\\nSuccesfully wrote \" + outfile + ', you can upload this file to the challenge competition website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPbuBux84cP5",
    "outputId": "b091126f-cef2-44f9-8286-68c6f3e9ab83"
   },
   "outputs": [],
   "source": [
    "# Comparison with baseline\n",
    "if __name__ == '__main__':\n",
    "    CSV_FILE_Y_TRUE = 'Data sets/Results/y_benchmark.csv'\n",
    "    CSV_FILE_Y_PRED = 'Results/new_experiment/final_gru_results.csv'\n",
    "    df_y_true = pd.read_csv(CSV_FILE_Y_TRUE, index_col=0, sep=',')\n",
    "    df_y_pred = pd.read_csv(CSV_FILE_Y_PRED, index_col=0, sep=',')\n",
    "    print(dreem_sleep_apnea_custom_metric(df_y_true, df_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RP.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
